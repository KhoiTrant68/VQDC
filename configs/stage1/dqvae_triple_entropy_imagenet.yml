model:
  target: models.stage1.triple_dqvae_entropy.TripleGrainVQModel
  params:
    encoderconfig:
      target: modules.dynamic.encoder_triple.TripleGrainEncoder
      params:
        ch: 128
        ch_mult: [1,1,2,2,4,4]
        num_res_blocks: 2
        attn_resolutions: [8,16,32]
        dropout: 0.0
        resamp_with_conv: true
        in_channels: 3
        resolution: 256
        z_channels: 256
        router_config:
          target: modules.dynamic.router_triple.TripleGrainDynamicEntropyRouter
          params:
            json_path: entropy_threshold/entropy_thresholds_imagenet_train_patch-16.json
            fine_grain_ratio_min: 0.01
            fine_grain_ratio_max: 0.99
    decoderconfig:
      target: modules.dynamic.decoder.Decoder
      params:
        ch: 128
        in_ch: 256
        out_ch: 3
        ch_mult: [1,1,2,2]
        num_res_blocks: 2
        resolution: 256
        attn_resolutions: [32]
        latent_size: 32
        window_size: 2
        position_type: fourier+learned
    lossconfig:
      target: modules.losses.vqperceptual_muldisc.VQLPIPSWithDiscriminator
      params:
        disc_start: 0
        disc_config:
          target: modules.discriminator.discriminator_model.NLayerDiscriminator
          params:
            input_nc: 3
            ndf: 64
            n_layers: 3
            use_actnorm: false
        disc_init: true
        codebook_weight: 1.0
        pixelloss_weight: 1.0
        disc_factor: 1.0
        disc_weight: 1.0
        perceptual_weight: 1.0
        disc_conditional: false
        disc_loss: hinge
        disc_weight_max: 0.75
        budget_loss_config:
          target: modules.dynamic.budget.BudgetConstraint_NormedSeperateRatioMSE_TripleGrain
          params:
            target_fine_ratio: 0.3
            target_median_ratio: 0.3
            gamma: 1.0
            min_grain_size: 8
            median_grain_size: 16
            max_grain_size: 32

    vqconfig:
      target: modules.vector_quantize.mask_vector_quantize.MaskVectorQuantize
      # target: modules.vector_quantization.quantize_codebook_mask.MaskVectorQuantize
      params:
        codebook_size: 1024
        codebook_dim: 256
        channel_last: false
        accept_image_fmap: true
        commitment_beta: 0.25
        # decay: 0.99
        # restart_unused_codes: True
        orthogonal_reg_weight: 0.
        activate_mask_quantize: True

    quant_before_dim: 256
    quant_after_dim: 256
    quant_sample_temperature: 0.0
    image_key: input

scheduler:
  base_learning_rate: 4.5e-06
  warmup_epochs: 5
  warmup_epochs_ratio: 0.1
  scheduler_type: linear-warmup_cosine-decay

data:
  target: data.data_builder.DataModuleFromConfig
  params:
    batch_size: 2
    num_workers: 4
    train:
      target: data.imagenet.ImageNetDataset
      params:
        split: train
        config:
          size: 256
    val:
      target: data.imagenet.ImageNetDataset
      params:
        split: val
        config:
          size: 256
